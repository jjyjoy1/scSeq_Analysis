# Single-cell RNA-seq Analysis Pipeline with VAEs and DCAs

This pipeline outlines a comprehensive approach to single-cell RNA sequencing (scRNA-seq) data analysis focused on noise reduction, dropout handling, and batch effect correction using Variational Autoencoders (VAEs)/scVI and Deep Count Autoencoders (DCAs).

## Table of Contents
1. [Overview](#overview)
2. [Setup and Installation](#setup-and-installation)
3. [Data Acquisition](#data-acquisition)
4. [Quality Control and Preprocessing](#quality-control-and-preprocessing)
5. [Denoising with Deep Count Autoencoder (DCA)](#denoising-with-deep-count-autoencoder-dca)
6. [Batch Correction with scVI](#batch-correction-with-scvi)
7. [Downstream Analysis](#downstream-analysis)
8. [Visualization and Evaluation](#visualization-and-evaluation)
9. [References](#references)

## Overview

Single-cell RNA sequencing technologies have revolutionized our ability to study gene expression at the cellular level. However, they come with technical challenges:

- **Noise and Dropouts**: Technical variability and high dropout rates can mask biological signals
- **Batch Effects**: Systematic variations between different experiments
- **High Dimensionality**: Thousands of genes across thousands of cells

In this pipeline, we leverage deep learning approaches to address these challenges:

1. **Deep Count Autoencoders (DCA)** for denoising and imputation
2. **Variational Autoencoders (VAE)** via scVI for batch effect correction and dimensionality reduction

This end-to-end workflow starts from raw count matrices and produces cleaned, batch-corrected data ready for downstream analysis.

## Setup and Installation

### Setting Up Environment

```bash
# Create and activate a new conda environment
conda create -n scrna_vae python=3.8
conda activate scrna_vae

# Install key packages
pip install scanpy anndata numpy scipy pandas matplotlib seaborn scikit-learn
pip install torch torchvision
pip install dca scvi-tools
```

### Importing Required Libraries

```python
import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import scanpy as sc
import anndata as ad
from scipy import sparse

# For DCA
import dca

# For scVI
import scvi
import torch

# Set random seed for reproducibility
np.random.seed(42)
torch.manual_seed(42)
```

## Data Acquisition

For this pipeline, we'll use the human pancreas scRNA-seq datasets commonly used as benchmarks for batch effect correction. These datasets were generated by different labs with different scRNA-seq protocols.

```python
# Set the working directory
work_dir = "pancreas_analysis"
os.makedirs(work_dir, exist_ok=True)
os.chdir(work_dir)

# Using Scanpy to load datasets from publicly available sources
# For this example, we'll load datasets from Baron, Muraro, and Segerstolpe studies
adata_baron = sc.read("baron_human_pancreas.h5ad")  # Load Baron dataset
adata_muraro = sc.read("muraro_human_pancreas.h5ad")  # Load Muraro dataset
adata_segerstolpe = sc.read("segerstolpe_human_pancreas.h5ad")  # Load Segerstolpe dataset

# Alternative: Load datasets using the scRNAseq package in R and convert to AnnData
# In R: library(scRNAseq); baron <- BaronPancreasData()
# Then save and import to Python

# Alternatively, we can use the scvi-tools datasets
adata_baron = scvi.data.pancreas_baron()
adata_muraro = scvi.data.pancreas_muraro()
adata_segerstolpe = scvi.data.pancreas_segerstolpe()

# Print basic information about datasets
print(f"Baron dataset: {adata_baron.shape[0]} cells, {adata_baron.shape[1]} genes")
print(f"Muraro dataset: {adata_muraro.shape[0]} cells, {adata_muraro.shape[1]} genes")
print(f"Segerstolpe dataset: {adata_segerstolpe.shape[0]} cells, {adata_segerstolpe.shape[1]} genes")
```

## Quality Control and Preprocessing

### Basic QC

```python
# Function to perform QC and filtering
def qc_and_filter(adata, min_genes=200, min_cells=3, max_percent_mito=20):
    print(f"Before QC: {adata.shape[0]} cells, {adata.shape[1]} genes")
    
    # Calculate QC metrics
    sc.pp.calculate_qc_metrics(adata, inplace=True)
    
    # Calculate percentage of mitochondrial genes
    adata.var['mt'] = adata.var_names.str.startswith('MT-')
    sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True)
    
    # Filter cells
    adata = adata[adata.obs.n_genes_by_counts > min_genes]
    adata = adata[adata.obs.pct_counts_mt < max_percent_mito]
    
    # Filter genes
    sc.pp.filter_genes(adata, min_cells=min_cells)
    
    print(f"After QC: {adata.shape[0]} cells, {adata.shape[1]} genes")
    return adata

# Apply QC to each dataset
adata_baron = qc_and_filter(adata_baron)
adata_muraro = qc_and_filter(adata_muraro)
adata_segerstolpe = qc_and_filter(adata_segerstolpe)
```

### Gene Selection and Data Harmonization

```python
# Find common genes across datasets
common_genes = list(set(adata_baron.var_names) & 
                   set(adata_muraro.var_names) & 
                   set(adata_segerstolpe.var_names))
print(f"Number of common genes: {len(common_genes)}")

# Subset datasets to common genes
adata_baron = adata_baron[:, common_genes]
adata_muraro = adata_muraro[:, common_genes]
adata_segerstolpe = adata_segerstolpe[:, common_genes]

# Add batch labels
adata_baron.obs['batch'] = 'baron'
adata_muraro.obs['batch'] = 'muraro'
adata_segerstolpe.obs['batch'] = 'segerstolpe'

# Harmonize cell type labels if available (adjust based on dataset-specific annotations)
cell_type_map = {
    # Define cell type mapping across datasets for consistent annotation
}

# Concatenate datasets
adata_combined = ad.concat(
    [adata_baron, adata_muraro, adata_segerstolpe],
    label="batch",
    keys=["baron", "muraro", "segerstolpe"],
    index_unique="-"
)

# Basic preprocessing
sc.pp.normalize_total(adata_combined, target_sum=1e4)
sc.pp.log1p(adata_combined)
```

## Denoising with Deep Count Autoencoder (DCA)

Deep Count Autoencoder (DCA) offers denoising and imputation with a zero-inflated negative binomial model that accounts for the count structure and dropout characteristics of scRNA-seq data.

```python
# DCA requires raw counts (not normalized or log-transformed)
# Create a copy for DCA
adata_for_dca = adata_combined.copy()
# Make sure we work with the raw counts
if 'counts' in adata_for_dca.layers:
    adata_for_dca.X = adata_for_dca.layers['counts']
else:
    # If raw counts aren't stored in layers, just use X if it's not normalized
    pass

# Run DCA denoising
dca.api.dca(
    adata_for_dca,
    mode='denoise',         # 'denoise' or 'latent' for dimensionality reduction
    ae_type='zinb-conddisp', # zero-inflated negative binomial with conditional dispersion
    normalize_per_cell=True,
    scale=True,
    hidden_size=(64, 32, 64), # Architecture: encoder and decoder layers
    hidden_dropout=0.1,
    batchnorm=True,
    activation='relu',
    init='glorot_uniform',
    verbose=True
)

# DCA adds denoised counts to .raw.X
# Transfer denoised counts to main AnnData object
adata_combined.layers['denoised'] = adata_for_dca.X.copy()

# Let's also save DCA latent space for visualization later
adata_combined.obsm['X_dca'] = adata_for_dca.obsm['X_dca']

# Visualize original vs denoised data
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))

sc.pp.highly_variable_genes(adata_combined, flavor='seurat', n_top_genes=2000)
sc.pp.pca(adata_combined, use_highly_variable=True)
sc.pp.neighbors(adata_combined)
sc.tl.umap(adata_combined)

# Original data
sc.pl.umap(adata_combined, color='batch', title='Original Data', ax=ax1, show=False)

# Denoised data (using DCA latent representation)
sc.pl.embedding(adata_combined, 'X_dca', color='batch', title='DCA Denoised', ax=ax2, show=False)

plt.tight_layout()
plt.savefig('dca_denoising_comparison.png', dpi=300)
plt.show()
```

## Batch Correction with scVI

scVI (single-cell Variational Inference) is a powerful tool that uses a variational autoencoder framework to integrate multiple scRNA-seq datasets, correct for batch effects, and perform dimensionality reduction.

```python
# Set up scVI
scvi.settings.seed = 42
scvi.settings.figdir = 'figures/'

# Pre-process data for scVI (use raw counts)
adata_for_scvi = adata_combined.copy()
if 'counts' in adata_for_scvi.layers:
    adata_for_scvi.X = adata_for_scvi.layers['counts'].copy()

# Set up scVI with batch information
scvi.model.SCVI.setup_anndata(
    adata_for_scvi,
    batch_key='batch',
    labels_key='cell_type' if 'cell_type' in adata_for_scvi.obs.columns else None
)

# Train the scVI model
vae = scvi.model.SCVI(adata_for_scvi)
vae.train(
    max_epochs=400,
    train_size=0.9,
    early_stopping=True,
    early_stopping_patience=20
)

# Get latent representation and add to original AnnData
adata_combined.obsm['X_scVI'] = vae.get_latent_representation()

# Get corrected expression values
# This gives us normalized data that is corrected for batch effects
corrected_data = vae.get_normalized_expression(
    library_size="latent",  # Use the latent library size for normalization
    transform_batch="batch_0"  # Transform all batches to reference batch
)
adata_combined.layers['scVI_corrected'] = corrected_data.values

# Visualize batch correction
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))

# Original data
sc.pl.umap(adata_combined, color='batch', title='Original Embedding', ax=ax1, show=False)

# scVI corrected data
sc.pp.neighbors(adata_combined, use_rep='X_scVI')
sc.tl.umap(adata_combined)
sc.pl.umap(adata_combined, color='batch', title='scVI Corrected', ax=ax2, show=False)

plt.tight_layout()
plt.savefig('scvi_batch_correction.png', dpi=300)
plt.show()

# If cell type labels are available, visualize them too
if 'cell_type' in adata_combined.obs.columns:
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))
    sc.pl.umap(adata_combined, color='cell_type', title='Cell Types (Original)', ax=ax1, show=False)
    
    # Recalculate neighbors and UMAP using scVI latent space
    sc.pp.neighbors(adata_combined, use_rep='X_scVI')
    sc.tl.umap(adata_combined)
    sc.pl.umap(adata_combined, color='cell_type', title='Cell Types (scVI)', ax=ax2, show=False)
    
    plt.tight_layout()
    plt.savefig('celltype_visualization.png', dpi=300)
    plt.show()
```

## Downstream Analysis

### Clustering

```python
# Clustering using scVI latent representation
sc.pp.neighbors(adata_combined, use_rep='X_scVI', n_neighbors=15)
sc.tl.leiden(adata_combined, resolution=0.8)

# Visualize clusters
sc.pl.umap(adata_combined, color=['leiden', 'batch'], ncols=1, title=['Clusters', 'Batch'])
plt.savefig('clustering_results.png', dpi=300)

# Check cluster composition by batch
cluster_batch = pd.crosstab(
    adata_combined.obs['leiden'],
    adata_combined.obs['batch'],
    normalize='index'
)
plt.figure(figsize=(10, 6))
cluster_batch.plot(kind='bar', stacked=True)
plt.title('Cluster Composition by Batch')
plt.xlabel('Cluster')
plt.ylabel('Proportion')
plt.savefig('cluster_batch_composition.png', dpi=300)
plt.show()
```

### Differential Expression Analysis

```python
# Differential expression analysis using corrected data
# Save the original X
original_X = adata_combined.X.copy()

# Use scVI corrected data for DE analysis
adata_combined.X = adata_combined.layers['scVI_corrected'].copy()

# Perform DE analysis
marker_genes = {}
for cluster in adata_combined.obs['leiden'].unique():
    sc.tl.rank_genes_groups(
        adata_combined,
        groupby='leiden',
        groups=[cluster],
        reference='rest',
        method='wilcoxon'
    )
    # Get top 20 genes for each cluster
    marker_genes[cluster] = sc.get.rank_genes_groups_df(
        adata_combined,
        group=cluster
    ).sort_values('scores', ascending=False).head(20)

# Visualize top marker genes
sc.pl.rank_genes_groups_heatmap(
    adata_combined,
    n_genes=5,
    groupby='leiden',
    show_gene_labels=True,
    figsize=(12, 8)
)
plt.savefig('marker_genes_heatmap.png', dpi=300)

# Restore original X
adata_combined.X = original_X
```

## Visualization and Evaluation

### Evaluating Batch Correction

```python
# Calculate batch mixing metrics

# 1. Silhouette Score (by batch)
from sklearn.metrics import silhouette_score
batch_labels = pd.Categorical(adata_combined.obs['batch']).codes
sil_score = silhouette_score(
    adata_combined.obsm['X_scVI'],
    batch_labels
)
print(f"Silhouette Score (batch, lower is better): {sil_score:.4f}")

# 2. kBET (requires R package kBET)
# We'll approximate this with Python implementation or skip if not available

# 3. Calculate Local Inverse Simpson's Index (LISI)
def calculate_lisi(X, batch_labels, n_neighbors=30):
    """Approximate LISI by calculating diversity of batches in local neighborhoods"""
    from sklearn.neighbors import NearestNeighbors
    import numpy as np
    
    # Get nearest neighbors
    nn = NearestNeighbors(n_neighbors=n_neighbors)
    nn.fit(X)
    distances, indices = nn.kneighbors(X)
    
    # Calculate LISI
    lisi_scores = []
    for i in range(len(X)):
        neighbor_batches = batch_labels[indices[i]]
        batch_counts = np.unique(neighbor_batches, return_counts=True)[1]
        batch_proportions = batch_counts / batch_counts.sum()
        simpson_index = np.sum(batch_proportions**2)
        lisi = 1 / simpson_index
        lisi_scores.append(lisi)
    
    return np.mean(lisi_scores)

lisi_score = calculate_lisi(adata_combined.obsm['X_scVI'], batch_labels)
print(f"LISI Score (batch, higher is better): {lisi_score:.4f}")

# Compare with uncorrected PCA
sc.pp.pca(adata_combined)
lisi_pca = calculate_lisi(adata_combined.obsm['X_pca'], batch_labels)
print(f"LISI Score for uncorrected PCA: {lisi_pca:.4f}")
```

### Comparison of Different Methods

```python
# Compare original, DCA, and scVI latent spaces
from sklearn.manifold import TSNE

# Calculate t-SNE for each representation
tsne_orig = TSNE(n_components=2, random_state=42).fit_transform(adata_combined.obsm['X_pca'])
tsne_dca = TSNE(n_components=2, random_state=42).fit_transform(adata_combined.obsm['X_dca'])
tsne_scvi = TSNE(n_components=2, random_state=42).fit_transform(adata_combined.obsm['X_scVI'])

# Store the t-SNE coordinates
adata_combined.obsm['X_tsne_pca'] = tsne_orig
adata_combined.obsm['X_tsne_dca'] = tsne_dca
adata_combined.obsm['X_tsne_scvi'] = tsne_scvi

# Visualize the t-SNE representations
fig, axes = plt.subplots(1, 3, figsize=(18, 5))

for i, (title, key) in enumerate([
    ('Original (PCA)', 'X_tsne_pca'),
    ('DCA', 'X_tsne_dca'),
    ('scVI', 'X_tsne_scvi')
]):
    ax = axes[i]
    ax.scatter(
        adata_combined.obsm[key][:, 0],
        adata_combined.obsm[key][:, 1],
        c=[{'baron': 'red', 'muraro': 'blue', 'segerstolpe': 'green'}[b] for b in adata_combined.obs['batch']],
        alpha=0.5,
        s=10
    )
    ax.set_title(title)
    ax.set_xticks([])
    ax.set_yticks([])
    
    # Add batch mixing score 
    lisi = calculate_lisi(adata_combined.obsm[key], batch_labels)
    ax.text(0.05, 0.95, f"LISI: {lisi:.2f}", transform=ax.transAxes, fontsize=10, 
            verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))

plt.tight_layout()
plt.savefig('method_comparison.png', dpi=300)
plt.show()
```

## References

1. Lopez et al. (2018). "Deep generative modeling for single-cell transcriptomics." Nature Methods.
2. Eraslan et al. (2019). "Single-cell RNA-seq denoising using a deep count autoencoder." Nature Communications.
3. Baron et al. (2016). "A Single-Cell Transcriptomic Map of the Human and Mouse Pancreas Reveals Inter- and Intra-cell Population Structure." Cell Systems.
4. Muraro et al. (2016). "A Single-Cell Transcriptome Atlas of the Human Pancreas." Cell Systems.
5. Segerstolpe et al. (2016). "Single-Cell Transcriptome Profiling of Human Pancreatic Islets in Health and Type 2 Diabetes." Cell Metabolism.
6. Tran et al. (2020). "A benchmark of batch-effect correction methods for single-cell RNA sequencing data." Genome Biology.
